---
title: "Modeling Ordered Ratings using Proportional Odds Regression"
author: "Keith McNulty"
output:
  xaringan::moon_reader:
    css: style.css
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---

```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
knitr::opts_chunk$set(warning = FALSE, message = FALSE)

```

class: left, middle, r-logo

## Note on source

This document is a summary learning developed for the NY Strategic HR Analytics Meetup on 15 January 2021.  It is based on material in the open source book *[Handbook for Regression Modeling in People Analytics](http://peopleanalytics-regression-book.org)*. Please consult this book for a deeper understanding/treatment. 

## Note on languages

This document is coded in R.  The model type used in this document (proportional odds logistic regression) is not currently well supported in Python.  It will become available in the next release of the `statsmodels` package.


---
class: left, middle, r-logo

## Example data set:  salespeople performance ratings

Let's look at some data that relates to the performance ratings of sales people in an organization on a scale of 1 to 5 of increasing performance:

```{r}
## download data
url <- "https://raw.githubusercontent.com/keithmcnulty/peopleanalytics-regression-book/master/presentations/employee_performance.csv"

employee_performance <- read.csv(url)

## look at the data
head(employee_performance)
```

We are being asked which of the other four factors influence the performance rating and how do they influence it.

---
class: left, middle, r-logo

## What does our data look like?

```{r}
## look at the data type - are they appropriate?
str(employee_performance)
```

---
class: left, middle, r-logo

## Adjusting data types for appropriate modeling

We need to make sure that `region` and `gender` is understood as an **unordered** categorical column of data.  We also need to make sure that the `rating` column is understood as an **ordered** categorical column.

```{r}
## unordered categories
cat_columns <- c("region", "gender")
employee_performance[cat_columns] <- 
  lapply(employee_performance[cat_columns], 
         as.factor)

## ordered categories
employee_performance$rating <- 
  ordered(employee_performance$rating,
          levels = 1:5)

str(employee_performance)
```

---
class: left, middle, r-logo

## Quick visualizations of bivariate relationships in the data

```{r, fig.height=6, fig.align = "center"}
library(GGally)

## create a pairplot
GGally::ggpairs(employee_performance)
```

---
class: left, middle, r-logo

## We want to answer a few questions as precisely as we can

1.  Which variables are meaningful in explaining employee performance? 
2.  To what extent does each meaningful variable influence performance?
3.  How much of the entire variance of performance do these variables explain?

---
class: left, middle, r-logo

## First we need to select the right type of model

Through asking some questions about the data that we have, we can determine an appropriate model to use.

**Question 1:** What type of outcome are we studying?  *Ordered categories* 

**Question 2:** Can we assume that each input acts similarly on each level of the outcome?  *Yes for now and we can check this later.  This is called the proportional odds assumption*.

Then we should use a proportional odds logistic regression model. This model will tell us how each input variable affects the *odds of someone having a higher performance rating*.

---
class: left, middle, r-logo

## Run the model

We can use the `polr()` function from the `MASS` package to run the model.

```{r}
library(MASS)

# formula for the model
our_formula = "rating ~ ."

# run model
model <- polr(data = employee_performance,
              formula = our_formula)
```

Now we have model sitting ready to be viewed.

---
class: left, middle, r-logo

## Viewing and clarifying the results

I like to use the `broom` package to view model results in a tidy way and to easily add columns to the results.

```{r}
library(dplyr)
library(broom)

(model_results <- tidy(model) %>% 
    filter(coef.type == "coefficient"))
```

---
class: left, middle, r-logo

## Are variables significant in explaining performance?

To determine this we need to convert our `statistic` into a p-value, and determine if the p-value is less than an alpha which is usually 0.05.

```{r}
library(dplyr)

## add p-value
(model_results <- model_results %>% 
  dplyr::mutate(
    pval = (1 - pnorm(abs(statistic), 0, 1))*2
  ))
```

We can safely drop everything except `sales` and `new_customers`, because `region` and `gender` have no significant effect.

---
class: left, middle, r-logo

## Simplify the model

```{r}
simpler_formula <- "rating ~ sales + new_customers"

## create simpler model
simpler_model <- polr(data = employee_performance,
                     formula = simpler_formula)

## generate tidy results
(simpler_results <- tidy(simpler_model) %>% 
    filter(coef.type == "coefficient"))
```

---
class: left, middle, r-logo

## How does each variable affect performance?

We need to take exponents of the `estimate` to get an interpretable *odds ratio*.

```{r}
## create odds ratio column
(simpler_results <- simpler_results %>% 
   dplyr::mutate(
     odds_ratio = exp(estimate)
   ))
```
